{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":432296,"sourceType":"datasetVersion","datasetId":195056}],"dockerImageVersionId":31260,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-09T05:31:39.052435Z","iopub.execute_input":"2026-02-09T05:31:39.052959Z","iopub.status.idle":"2026-02-09T05:32:48.146715Z","shell.execute_reply.started":"2026-02-09T05:31:39.052931Z","shell.execute_reply":"2026-02-09T05:32:48.146093Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Create Dataset Loader","metadata":{}},{"cell_type":"markdown","source":"## Custom Dataset Loader","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom PIL import Image\n\nclass CustomImageDataset(Dataset):\n    def __init__(self, file_paths, labels, transform=None):\n        self.file_paths = file_paths\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.file_paths)\n\n    def __getitem__(self, idx):\n        img = Image.open(self.file_paths[idx]).convert(\"RGB\")\n        label = self.labels[idx]\n        if self.transform:\n            img = self.transform(img)\n        return img, label\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T05:32:48.147863Z","iopub.execute_input":"2026-02-09T05:32:48.148255Z","iopub.status.idle":"2026-02-09T05:32:51.592423Z","shell.execute_reply.started":"2026-02-09T05:32:48.148229Z","shell.execute_reply":"2026-02-09T05:32:51.591852Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Transformations","metadata":{}},{"cell_type":"code","source":"import torchvision.transforms as T\ntransform = T.Compose([T.Resize(64),\n                     T.ToTensor(),\n                     T.Normalize([0.5,0.5,0.5],\n                                  [0.5,0.5,0.5]),\n                     ])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T05:32:51.593422Z","iopub.execute_input":"2026-02-09T05:32:51.593904Z","iopub.status.idle":"2026-02-09T05:32:54.994049Z","shell.execute_reply.started":"2026-02-09T05:32:51.593872Z","shell.execute_reply":"2026-02-09T05:32:54.993447Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Dataset Loader","metadata":{}},{"cell_type":"code","source":"# import libraries\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# for importing data\nimport torchvision\nimport torchvision.transforms as T\nfrom torch.utils.data import DataLoader,Subset\n\nimport sys\n\nimport matplotlib.pyplot as plt\nimport matplotlib_inline.backend_inline\nmatplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n\nbatch_size = 128\n\nimport os\n\n# Get all image file paths from the directory\nimage_folder = '/kaggle/input/anime-faces/data'\nfile_paths = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.endswith('.png')]\n\n# Create dummy labels \nlabels = [1] * len(file_paths) \n\n# Create Object\ntrue_data = CustomImageDataset(file_paths=file_paths, labels=labels, transform=transform)\n\n# Create Loader\ntrue_data_loader = DataLoader(true_data, batch_size=batch_size, shuffle=True ,drop_last = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T05:32:54.995553Z","iopub.execute_input":"2026-02-09T05:32:54.995901Z","iopub.status.idle":"2026-02-09T05:32:55.029045Z","shell.execute_reply.started":"2026-02-09T05:32:54.995877Z","shell.execute_reply":"2026-02-09T05:32:55.028503Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Visualize Input","metadata":{}},{"cell_type":"code","source":"X,y = next(iter(true_data_loader))\nfig,axs = plt.subplots(3,6,figsize=(10,6))\nfor (i,ax) in enumerate(axs.flatten()):\n    img = X[i] \n    # Un-normalize \n    img = img / 2 + 0.5\n    label = y[i]\n    # show the data\n    ax.imshow(img.permute(1, 2, 0).numpy())\n    ax.text(14,0,label,ha='center',fontweight='bold',color='k',backgroundcolor='y')\n    ax.axis('off')\nplt.savefig('old_faces.png')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T05:32:55.029967Z","iopub.execute_input":"2026-02-09T05:32:55.030713Z","iopub.status.idle":"2026-02-09T05:32:56.443266Z","shell.execute_reply.started":"2026-02-09T05:32:55.030687Z","shell.execute_reply":"2026-02-09T05:32:56.442276Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Create Model","metadata":{}},{"cell_type":"markdown","source":"## Discriminator Class","metadata":{}},{"cell_type":"code","source":"class discriminatorNet(nn.Module):\n  def __init__(self):\n    super().__init__()\n\n    # convolution layers\n    self.conv1 = nn.Conv2d(  3, 64, 4, 2, 1, bias=False)\n    self.conv2 = nn.Conv2d( 64,128, 4, 2, 1, bias=False)\n    self.conv3 = nn.Conv2d(128,256, 4, 2, 1, bias=False)\n    self.conv4 = nn.Conv2d(256,512, 4, 2, 1, bias=False)\n    self.conv5 = nn.Conv2d(512,  1, 4, 1, 0, bias=False)\n\n    # batchnorm\n    self.bn2 = nn.BatchNorm2d(128)\n    self.bn3 = nn.BatchNorm2d(256)\n    self.bn4 = nn.BatchNorm2d(512)\n    \n  def forward(self,x):\n    x = F.leaky_relu( self.conv1(x) ,.2)\n    x = F.leaky_relu( self.conv2(x) ,.2)\n    x = self.bn2(x)\n    x = F.leaky_relu( self.conv3(x) ,.2)\n    x = self.bn3(x)\n    x = F.leaky_relu( self.conv4(x) ,.2)\n    x = self.bn4(x)\n    return torch.sigmoid( self.conv5(x) ).view(-1,1)\n\n\ndnet = discriminatorNet()\ny = dnet(torch.randn(10,3,64,64))\ny.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T05:32:56.444309Z","iopub.execute_input":"2026-02-09T05:32:56.444902Z","iopub.status.idle":"2026-02-09T05:32:56.576729Z","shell.execute_reply.started":"2026-02-09T05:32:56.444864Z","shell.execute_reply":"2026-02-09T05:32:56.575945Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Generator Class","metadata":{}},{"cell_type":"code","source":"class generatorNet(nn.Module):\n  def __init__(self):\n    super().__init__()\n\n    # convolution layers\n    self.conv1 = nn.ConvTranspose2d(100,512, 4, 1, 0, bias=False)\n    self.conv2 = nn.ConvTranspose2d(512,256, 4, 2, 1, bias=False)\n    self.conv3 = nn.ConvTranspose2d(256,128, 4, 2, 1, bias=False)\n    self.conv4 = nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False)\n    self.conv5 = nn.ConvTranspose2d(64,   3, 4, 2, 1, bias=False)\n\n    # batchnorm\n    self.bn1 = nn.BatchNorm2d(512)\n    self.bn2 = nn.BatchNorm2d(256)\n    self.bn3 = nn.BatchNorm2d(128)\n    self.bn4 = nn.BatchNorm2d( 64)\n\n\n  def forward(self,x):\n    x = F.relu( self.bn1(self.conv1(x)) )\n    x = F.relu( self.bn2(self.conv2(x)) )\n    x = F.relu( self.bn3(self.conv3(x)) )\n    x = F.relu( self.bn4(self.conv4(x)) )\n    x = torch.tanh( self.conv5(x) )\n    return x\n    \n\ngnet = generatorNet()\ny = gnet(torch.randn(10,100,1,1))\nimg = y[0].permute(1,2,0).detach().numpy()\nimg = img/2 + 0.5\nplt.imshow(img)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T05:32:56.577843Z","iopub.execute_input":"2026-02-09T05:32:56.578118Z","iopub.status.idle":"2026-02-09T05:32:56.812356Z","shell.execute_reply.started":"2026-02-09T05:32:56.578095Z","shell.execute_reply":"2026-02-09T05:32:56.811705Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"markdown","source":"## Metaparameters","metadata":{}},{"cell_type":"code","source":"lossfun = nn.BCELoss()\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndnet = discriminatorNet().to(device)\ngnet = generatorNet().to(device)\n\nd_optimizer = torch.optim.Adam(dnet.parameters(), lr=.0002, betas=(.5,.999))\ng_optimizer = torch.optim.Adam(gnet.parameters(), lr=.0002, betas=(.5,.999))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T05:54:33.482895Z","iopub.execute_input":"2026-02-09T05:54:33.483479Z","iopub.status.idle":"2026-02-09T05:54:33.538510Z","shell.execute_reply.started":"2026-02-09T05:54:33.483451Z","shell.execute_reply":"2026-02-09T05:54:33.537915Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training Loop","metadata":{}},{"cell_type":"code","source":"import torchvision.utils as vutils\nimport os\n\n# 1. Setup: Create a directory for results\noutput_dir = '/kaggle/working/gan_results'\nos.makedirs(output_dir, exist_ok=True)\n\n# 2. Setup: Fixed noise to track progress (e.g., a grid of 16 images)\nfixed_noise = torch.randn(16, 100, 1, 1).to(device)\n\n# number of epochs (expressed in number of batches)\n# num_epochs = int(4000/len(true_data_loader))\nnum_epochs = 100\nlosses  = []\ndisDecs = []\n\n\n\nfor epochi in range(num_epochs):\n\n  for data,_ in true_data_loader:\n    \n    # send data to GPU\n    data = data.to(device)\n\n    # create labels for real and fake images\n    real_labels = torch.full((batch_size,1),0.8,device = device)\n    fake_labels = torch.full((batch_size,1),0.2,device = device)\n\n\n\n    ### ---------------- Train the discriminator ---------------- ###\n\n    # forward pass and loss for REAL pictures\n    pred_real   = dnet(data)                     # output of discriminator\n    d_loss_real = lossfun(pred_real,real_labels) # all labels are 1\n\n    # forward pass and loss for FAKE pictures\n    fake_data   = torch.randn(batch_size,100,1,1).to(device) # random numbers to seed the generator\n    fake_images = gnet(fake_data)                           # output of generator\n    pred_fake   = dnet(fake_images)                         # pass through discriminator\n    d_loss_fake = lossfun(pred_fake,fake_labels)            # all labels are 0\n\n    # collect loss (using combined losses)\n    d_loss = d_loss_real + d_loss_fake\n\n    # backprop\n    d_optimizer.zero_grad()\n    d_loss.backward()\n    d_optimizer.step()\n\n\n\n    ### ---------------- Train the generator ---------------- ###\n\n    # create fake images and compute loss\n    fake_images = gnet(torch.randn(batch_size,100,1,1).to(device))\n    pred_fake   = dnet(fake_images)\n\n    # compute loss\n    g_loss = lossfun(pred_fake,real_labels)\n\n    # backprop\n    g_optimizer.zero_grad()\n    g_loss.backward()\n    g_optimizer.step()\n\n\n    # collect losses and discriminator decisions\n    losses.append([d_loss.item(),g_loss.item()])\n    \n    d1 = torch.mean((pred_real>.5).float()).detach().cpu().item()\n    d2 = torch.mean((pred_fake>.5).float()).detach().cpu().item()\n    disDecs.append([d1,d2])\n\n  gnet.eval() # Set to evaluation mode\n  with torch.no_grad():\n    # Generate images using the fixed noise\n    fake_samples = gnet(fixed_noise).cpu()\n    # Un-normalize from [-1, 1] to [0, 1] for visualization\n    fake_samples = fake_samples / 2 + 0.5\n        \n        # Create a grid and save\n    plt.figure(figsize=(8, 8))\n    grid = vutils.make_grid(fake_samples, nrow=4, padding=2)\n    plt.imshow(grid.permute(1, 2, 0))\n    plt.axis('off')\n    plt.title(f'Epoch {epochi+1}')\n        \n        # Save to Kaggle /working directory\n    plt.savefig(os.path.join(output_dir, f'epoch_{epochi+1}.png'))\n    plt.show() # Display in notebook\n    plt.close() # Close to save memory\n        \n  gnet.train() # Set back to training mode\n  msg = f'Finished epoch {epochi+1}/{num_epochs}'\n  sys.stdout.write('\\r' + msg)\n\n\n# convert performance from list to numpy array\nlosses  = np.array(losses)\ndisDecs = np.array(disDecs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T05:54:36.901393Z","iopub.execute_input":"2026-02-09T05:54:36.901963Z","iopub.status.idle":"2026-02-09T07:07:30.092288Z","shell.execute_reply.started":"2026-02-09T05:54:36.901936Z","shell.execute_reply":"2026-02-09T07:07:30.091398Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Result","metadata":{}},{"cell_type":"markdown","source":"## Loss Visualization","metadata":{}},{"cell_type":"code","source":"# create a 1D smoothing filter\ndef smooth(x,k=15):\n  return np.convolve(x,np.ones(k)/k,mode='same')\nfig,ax = plt.subplots(1,3,figsize=(18,5))\n\nax[0].plot(smooth(losses[:,0]))\nax[0].plot(smooth(losses[:,1]))\nax[0].set_xlabel('Batches')\nax[0].set_ylabel('Loss')\nax[0].set_title('Model loss')\nax[0].legend(['Discrimator','Generator'])\n\n\nax[1].plot(losses[::5,0],losses[::5,1],'k.',alpha=.1)\nax[1].set_xlabel('Discriminator loss')\nax[1].set_ylabel('Generator loss')\n\nax[2].plot(smooth(disDecs[:,0]))\nax[2].plot(smooth(disDecs[:,1]))\nax[2].set_xlabel('Epochs')\nax[2].set_ylabel('Probablity (\"real\")')\nax[2].set_title('Discriminator output')\nax[2].legend(['Real','Fake'])\nplt.savefig('loss_result.png')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T05:53:03.507850Z","iopub.execute_input":"2026-02-09T05:53:03.508084Z","iopub.status.idle":"2026-02-09T05:53:04.044530Z","shell.execute_reply.started":"2026-02-09T05:53:03.508062Z","shell.execute_reply":"2026-02-09T05:53:04.043792Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## New Images","metadata":{}},{"cell_type":"code","source":"gnet.eval() # Set to evaluation mode\nwith torch.no_grad():\n    fixed_noise = torch.randn(16, 100, 1, 1).to(device)\n    # Generate images using the fixed noise\n    fake_samples = gnet(fixed_noise).cpu()\n    # Un-normalize from [-1, 1] to [0, 1] for visualization\n    fake_samples = fake_samples / 2 + 0.5\n        \n        # Create a grid and save\n    plt.figure(figsize=(8, 8))\n    grid = vutils.make_grid(fake_samples, nrow=4, padding=2)\n    plt.imshow(grid.permute(1, 2, 0))\n    plt.axis('off')\n    plt.title(f'Epoch {epochi+1}')\n        \n        # Save to Kaggle /working directory\n    plt.savefig(os.path.join(output_dir, f'epoch_{epochi+1}.png'))\n    plt.show() # Display in notebook\n    plt.close() # Close to save memory","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T07:11:43.831652Z","iopub.execute_input":"2026-02-09T07:11:43.832332Z","iopub.status.idle":"2026-02-09T07:11:44.431165Z","shell.execute_reply.started":"2026-02-09T07:11:43.832300Z","shell.execute_reply":"2026-02-09T07:11:44.430403Z"}},"outputs":[],"execution_count":null}]}